{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read json containing title and description. See parse_metadata.py. Currently only processing title and description to reduce memory consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename='nasa_text2.json'\n",
    "mytext = pd.read_json(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peek json contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32084</th>\n",
       "      <td> Prognostics methodologies determine the health...</td>\n",
       "      <td> Implementation of Prognostic Methodologies to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32085</th>\n",
       "      <td> Studying and analyzing the ageing mechanisms o...</td>\n",
       "      <td> DIAGNOSTIC/PROGNOSTIC EXPERIMENTS FOR CAPACITO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32086</th>\n",
       "      <td> This paper discusses our initial efforts in co...</td>\n",
       "      <td> Prognostic Techniques for Capacitor Degradatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32087</th>\n",
       "      <td> This document outlines NASA's IT management an...</td>\n",
       "      <td> OCIO FITARA Common Baseline Implementation Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32088</th>\n",
       "      <td> This is an API for the Earth Polychromatic Ima...</td>\n",
       "      <td>                        EPIC Daily Blue Marble API</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "32084  Prognostics methodologies determine the health...   \n",
       "32085  Studying and analyzing the ageing mechanisms o...   \n",
       "32086  This paper discusses our initial efforts in co...   \n",
       "32087  This document outlines NASA's IT management an...   \n",
       "32088  This is an API for the Earth Polychromatic Ima...   \n",
       "\n",
       "                                                   title  \n",
       "32084  Implementation of Prognostic Methodologies to ...  \n",
       "32085  DIAGNOSTIC/PROGNOSTIC EXPERIMENTS FOR CAPACITO...  \n",
       "32086  Prognostic Techniques for Capacitor Degradatio...  \n",
       "32087  OCIO FITARA Common Baseline Implementation Pla...  \n",
       "32088                         EPIC Daily Blue Marble API  \n",
       "\n",
       "[5 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytext.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32089\n"
     ]
    }
   ],
   "source": [
    "num_rows = mytext.title.count()\n",
    "print num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since processing all rows in the mytext dataframe kills the jupyter kernel due to large memory consumption, I'm taking only 50 random rows for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29397, 13510, 3719, 5484, 22113, 2468, 929, 24203, 11467, 754, 22888, 27960, 19439, 15474, 19383, 10916, 10801, 6153, 22037, 12571, 4534, 23975, 18252, 28541, 16950, 10785, 1284, 18320, 3690, 622, 9952, 674, 16291, 24788, 31365, 28933, 19653, 907, 139, 15680, 15223, 7260, 24489, 29647, 3406, 9174, 22735, 1635, 31572, 1810]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_indices = random.sample(xrange(num_rows), 50)\n",
    "print random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_sample = mytext.take(random_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download NLTK stopwords (only need this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alexisc/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk_stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top unique words in the 'title' field, not including nltk stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_title_count = text_sample['title'].apply(lambda x : pd.value_counts(x.split(\" \"))).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.25x1.25L42)     1\n",
      "(AIRS+AMSU+HSB)    1\n",
      "(AIRS-only)        1\n",
      "(C3PO)             1\n",
      "(eta               1\n",
      "0.25x0.25          1\n",
      "1.0x1.0            1\n",
      "1x1                1\n",
      "2                  1\n",
      "2/3x1/2L73)        1\n",
      "2001-2004          1\n",
      "3                  1\n",
      "3-Hourly           1\n",
      "3D                 2\n",
      "4                  1\n",
      "...\n",
      "air             1\n",
      "associated      1\n",
      "colonization    1\n",
      "coord,          1\n",
      "deg             3\n",
      "duration        1\n",
      "flight          1\n",
      "km              1\n",
      "long            1\n",
      "physical        2\n",
      "plants          1\n",
      "quality         1\n",
      "retrieval       2\n",
      "space           2\n",
      "standard        1\n",
      "Length: 239, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "non_stop_keys = sample_title_count[~sample_title_count.keys().isin(nltk_stop)]\n",
    "print non_stop_keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_stop_keys.sort(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project     12\n",
      "Data         6\n",
      "BOREAS       5\n",
      "Daily        5\n",
      "Grid         4\n",
      "Global       4\n",
      "V005         3\n",
      "LBA-ECO      3\n",
      "Level        3\n",
      "Water        3\n",
      "Control      3\n",
      "V003         3\n",
      "deg          3\n",
      "OMI/Aura     3\n",
      "Soil         3\n",
      "...\n",
      "PDS                    1\n",
      "Outputs                1\n",
      "Optimization           1\n",
      "NS001                  1\n",
      "Observation            1\n",
      "OSPO                   1\n",
      "OCTS_L3m_MO_POC_9km    1\n",
      "OCTS_L3b_SNWI_PIC      1\n",
      "OCEAN                  1\n",
      "Non                    1\n",
      "Nitrogen               1\n",
      "Nighttime              1\n",
      "New                    1\n",
      "Near                   1\n",
      "(1.25x1.25L42)         1\n",
      "Length: 239, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print non_stop_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top unique words in the 'description' field, not including nltk stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_desc_count = text_sample['description'].apply(lambda x : pd.value_counts(x.split(\" \"))).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            981\n",
      "data         80\n",
      "The          68\n",
      "product      33\n",
      "\\n           28\n",
      "MODIS        27\n",
      "This         21\n",
      "global       19\n",
      "contains     18\n",
      "NASA         17\n",
      "Data         17\n",
      "These        16\n",
      "based        16\n",
      "Earth        16\n",
      "daily        15\n",
      "...\n",
      "documentation     1\n",
      "documentation,    1\n",
      "double-quoted     1\n",
      "drag              1\n",
      "drastically       1\n",
      "draw              1\n",
      "due               1\n",
      "duration          1\n",
      "speculation       1\n",
      "easily            1\n",
      "eddy              1\n",
      "spectrum          1\n",
      "effective,        1\n",
      "effects           1\n",
      "deviation         1\n",
      "Length: 2308, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "desc_non_stop_keys = sample_desc_count[~sample_desc_count.keys().isin(nltk_stop)]\n",
    "desc_non_stop_keys.sort(ascending=False)\n",
    "print desc_non_stop_keys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove additional stop words from previous exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_stop_words = ['the','and','of','to','in','a','for','is','The','are','that','will','from','at','on','product','with','\\n','be','were','by','This','was','this','or','These','over','other','used','use','files','as','file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              981\n",
      "data           80\n",
      "MODIS          27\n",
      "global         19\n",
      "contains       18\n",
      "NASA           17\n",
      "Data           17\n",
      "based          16\n",
      "Earth          16\n",
      "daily          15\n",
      "gridded        13\n",
      "Phase          13\n",
      "instrument     13\n",
      "Aqua           12\n",
      "design         12\n",
      "...\n",
      "modifications    1\n",
      "modify           1\n",
      "modular,         1\n",
      "moisture,        1\n",
      "momentum         1\n",
      "monitoring       1\n",
      "monitoring,      1\n",
      "monoxide         1\n",
      "months           1\n",
      "model.           1\n",
      "moons            1\n",
      "moving           1\n",
      "much             1\n",
      "multi-channel    1\n",
      "CMOS             1\n",
      "Length: 2299, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "desc_non_stop_keys = desc_non_stop_keys[~desc_non_stop_keys.keys().isin(my_stop_words)]\n",
    "desc_non_stop_keys.sort(ascending=False)\n",
    "print desc_non_stop_keys \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
