{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing topic prediction of NASA data metadata using LDA built on Wikipedia corpus\n",
    "\n",
    "- Data source:https://data.nasa.gov/data.json\n",
    "- Gensim tutorial: https://radimrehurek.com/gensim/wiki.html\n",
    "- Exploratory visualization: https://public.tableau.com/views/NASAOpenDataMetadatatopic-predictionusingLDAbuiltfromWikipediacorpus/Sheet4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json as json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data files\n",
    "These files are created by running parse_metadata.py which requires NASA's data to be saved as nasa_metadata2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keyworddf = pd.read_json('nasa_keyword.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titledf = pd.read_json('nasa_title.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descdf = pd.read_json('nasa_description.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for getting topic recommendations from documents\n",
    "Code modified from http://radimrehurek.com/topic_modeling_tutorial/2%20-%20Topic%20Modeling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import smart_open, simple_preprocess\n",
    "from gensim.corpora.wikicorpus import _extract_pages, filter_wiki\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n",
    "\n",
    "def iter_wiki(dump_file):\n",
    "    \"\"\"Yield each article from the Wikipedia dump, as a `(title, tokens)` 2-tuple.\"\"\"\n",
    "    ignore_namespaces = 'Wikipedia Category File Portal Template MediaWiki User Help Book Draft'.split()\n",
    "    for title, text, pageid in _extract_pages(smart_open(dump_file)):\n",
    "        text = filter_wiki(text)\n",
    "        tokens = tokenize(text)\n",
    "        if len(tokens) < 50 or any(title.startswith(ns + ':') for ns in ignore_namespaces):\n",
    "            continue  # ignore short articles and various meta-articles\n",
    "        yield title, tokens\n",
    "\n",
    "def rec_topic(doc, id2word, model):\n",
    "    bow = id2word.doc2bow(tokenize(doc))\n",
    "    doc_lda = model[bow]\n",
    "    try:\n",
    "        print(model.print_topic(max(doc_lda, key=lambda item: item[1])[0]))\n",
    "    except:\n",
    "        print (\"Error processing\", doc)\n",
    "        \n",
    "def get_topic_dict(doc, id2word, model):\n",
    "    bow = id2word.doc2bow(tokenize(doc))\n",
    "    doc_lda = model[bow]\n",
    "    topic_dict = {}\n",
    "    try:\n",
    "        id_tup = model.get_topic_terms(max(doc_lda, key=lambda item: item[1])[0])  \n",
    "        for item in id_tup:\n",
    "            topic_dict[id2word[item[0]]] = item[1]\n",
    "    except:\n",
    "        print (\"Error processing\", doc)\n",
    "    return topic_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dictionary and LDA model generated from Wikipedia tarballs\n",
    "See https://radimrehurek.com/gensim/wiki.html for how to generate an LDA model from the Wikipedia corpus.\n",
    "I did not set up the distributed version, so it took my linux VM ~12 hours to convert the corpus into sparse TF-IDF vectors (step 1). Then generating the LDA Model (Step 2) took about 12 hours as well. I've uploaded the resulting files, so you don't have to regenerate these files if you don't want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "id2word = gensim.corpora.Dictionary.load_from_text('wiki_en_wordids.txt.bz2')\n",
    "model = gensim.models.LdaModel.load('myldamodel.lda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of how the topic recommender works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USGS 15 minute stream flow data for Kings Creek on the Konza Prairie\n"
     ]
    }
   ],
   "source": [
    "# Example description text\n",
    "example_desc = descdf.description[0]\n",
    "print (example_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010*river + 0.008*lake + 0.006*creek + 0.005*park + 0.005*island + 0.005*mountain + 0.004*water + 0.004*reserve + 0.004*forest + 0.003*dam\n"
     ]
    }
   ],
   "source": [
    "# Example topics recommended for description\n",
    "rec_topic(example_desc, id2word, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare it with the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Minute Stream Flow Data: USGS (FIFE)\n"
     ]
    }
   ],
   "source": [
    "print(titledf.title[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare it with the keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'EARTH SCIENCE', u'HYDROSPHERE', u'SURFACE WATER']\n"
     ]
    }
   ],
   "source": [
    "print(keyworddf.keyword[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data structures to visualize topics predicted using the LDA model\n",
    "\n",
    "For this first exploratory visualization, I am ignoring probabilities associated with each topic from the LDA model output. This is important to note, as we will see from the visualization that some topics are completely incorrect. The question is did LDA predict those topics with lower probabilities than the other ones?\n",
    "\n",
    "This next cell took 5-8 hours to run. There are faster ways to do it, but I had other things to do, so I let this vm chug away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_rows = descdf.description.count()\n",
    "\n",
    "# Dictionary of topic to metadata id\n",
    "docid_topic = {}\n",
    "\n",
    "for i in range(0, num_rows): \n",
    "    # Print a . every 100 item, so that I know the notebook hasn't crashed\n",
    "    if i%100 == 0:\n",
    "        print ('.')\n",
    "    item_id = descdf.id[i]\n",
    "    \n",
    "    # The id from all dataframes should match since they should refer to the same entry from the source data.json\n",
    "    if (item_id != titledf.id[i] or item_id != keyworddf.id[i]):\n",
    "        print ('ID mismatch', item_id, titledf.id[i], keyworddf.id[i])\n",
    "        break\n",
    "    \n",
    "    desc_text = descdf.description[i]\n",
    "    title_text = titledf.title[i]\n",
    "    keywords = keyworddf.keyword[i]\n",
    "    \n",
    "    # Get the recommended topics in the structure of a dictionary, using the LDA model\n",
    "    desc_topic_dict = get_topic_dict(desc_text, id2word, model)\n",
    "    \n",
    "    ''' Each item in the data.json has a unique id. \n",
    "        docid_topic uses this unique id as a dictionary key.\n",
    "        to topic keys with a list.\n",
    "        Initialize the list if the item id is not in the dictionary'''\n",
    "    if item_id not in docid_topic.keys():\n",
    "        docid_topic[item_id] = []\n",
    "    \n",
    "    for key in desc_topic_dict:\n",
    "        if key not in docid_topic[item_id]:\n",
    "            docid_topic[item_id].append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write id:topics into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('docids_topic.csv', 'wb')\n",
    "fieldnames = ['doc_id', 'topics']\n",
    "w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "w.writeheader()\n",
    "\n",
    "for doc_id in docid_topic:    \n",
    "    # Encode list in utf-8. There are probably better ways to do this but I'm a python n00b\n",
    "    topiclist = docid_topic[doc_id]  \n",
    "    encodedlist = []\n",
    "    for x in topiclist:\n",
    "        encodedlist.append(x.encode('utf-8'))        \n",
    "    # Write the doc_id, encoded in utf-8 and the list of topics to csv\n",
    "    w.writerow({'doc_id': doc_id.encode('utf-8'), 'topics': encodedlist})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write other fields which may be interesting to visualize to csv\n",
    "This didn't work too well for the Description data frame, possibly due to the fact that some of the descriptions have '\\t' in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titledf.to_csv('nasa_title.csv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "descdf.to_csv('nasa_desc.csv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keyworddf.to_csv('nasa_keyword.csv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is when I realized the descdf also has its columns in the incorrect order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USGS 15 minute stream flow data for Kings Cree...</td>\n",
       "      <td>55942a57c63a7fe59b495a77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USGS 15 minute stream flow data for Kings Cree...</td>\n",
       "      <td>55942a57c63a7fe59b495a78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABSTRACT: USGS 15 minute stream flow data for ...</td>\n",
       "      <td>55942a58c63a7fe59b495a79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The 2000 Pilot Environmental Sustainability In...</td>\n",
       "      <td>55942a58c63a7fe59b495a7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 2000 Pilot Environmental Sustainability In...</td>\n",
       "      <td>55942a58c63a7fe59b495a7b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                        id\n",
       "0  USGS 15 minute stream flow data for Kings Cree...  55942a57c63a7fe59b495a77\n",
       "1  USGS 15 minute stream flow data for Kings Cree...  55942a57c63a7fe59b495a78\n",
       "2  ABSTRACT: USGS 15 minute stream flow data for ...  55942a58c63a7fe59b495a79\n",
       "3  The 2000 Pilot Environmental Sustainability In...  55942a58c63a7fe59b495a7a\n",
       "4  The 2000 Pilot Environmental Sustainability In...  55942a58c63a7fe59b495a7b"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we swap the pandas DataFrame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descdf2 = descdf[['id', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55942a57c63a7fe59b495a77</td>\n",
       "      <td>USGS 15 minute stream flow data for Kings Cree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55942a57c63a7fe59b495a78</td>\n",
       "      <td>USGS 15 minute stream flow data for Kings Cree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55942a58c63a7fe59b495a79</td>\n",
       "      <td>ABSTRACT: USGS 15 minute stream flow data for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55942a58c63a7fe59b495a7a</td>\n",
       "      <td>The 2000 Pilot Environmental Sustainability In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55942a58c63a7fe59b495a7b</td>\n",
       "      <td>The 2000 Pilot Environmental Sustainability In...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                                        description\n",
       "0  55942a57c63a7fe59b495a77  USGS 15 minute stream flow data for Kings Cree...\n",
       "1  55942a57c63a7fe59b495a78  USGS 15 minute stream flow data for Kings Cree...\n",
       "2  55942a58c63a7fe59b495a79  ABSTRACT: USGS 15 minute stream flow data for ...\n",
       "3  55942a58c63a7fe59b495a7a  The 2000 Pilot Environmental Sustainability In...\n",
       "4  55942a58c63a7fe59b495a7b  The 2000 Pilot Environmental Sustainability In..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descdf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Write the description DataFrame to csv the old-fashioned way since DataFrame.to_csv didn't work out too well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('nasa_desc3.csv', 'wb')\n",
    "fieldnames = ['doc_id', 'description']\n",
    "w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "\n",
    "w.writeheader()\n",
    "\n",
    "for index, row in descdf2.iterrows():\n",
    "    w.writerow({'doc_id': row['id'].encode('utf-8'), 'description': row['description'].encode('utf-8')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After having fun visualizing the data in Tableau, I decided to add even more properties from the source data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keyworddf.to_csv('nasa_keywords.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_json('nasa_spatial.json').to_csv('nasa_spatial.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_json('nasa_theme.json').to_csv('nasa_theme.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_json('nasa_temporal.json').to_csv('nasa_temporal.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_json('nasa_landingPage.json').to_csv('nasa_landingPage.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you know how to embed Tableau visualizations in Jupyter notebook, send me a note!\n",
    "\n",
    "Here's a visualization of how the keywords (human-tagged) match with the topics generated by LDA build from the wikipedia corpus https://public.tableau.com/views/NASAOpenDataMetadatatopic-predictionusingLDAbuiltfromWikipediacorpus/Sheet4\n",
    "Some of the topic prediction are not very successful. For example, hover over [dashlink, Ames] \n",
    "\n",
    "Here's a visualization of how the titles (human-supplied) match with the LDA build from the wikipedia corpus\n",
    "The size of each circle is scaled by the number of records with the same title\n",
    "https://public.tableau.com/views/NASAOpenDataMetadatatopic-predictionusingLDAbuiltfromWikipediacorpus/Sheet4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau didn't like the format of the spatial field, so let's reformat it\n",
    "The simplest approach is to assume that there is an array of doubles, split them into two and consider the first half of the array the latitude, and the second half is the longitude. \n",
    "This seems to work for the first 5 entries in the DataFrame, even though note that some of them are comma-delimited, and some are just space-delimited.\n",
    "However, we will see that this assumption does not hold true for many entries.\n",
    "For exploratory visualization I'm just ignoring those entries. \n",
    "For real data analysis, those entries should be correctly parsed as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spatialdf = pd.read_json('nasa_spatial.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spatial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55942a57c63a7fe59b495a77</td>\n",
       "      <td>39.1 -96.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55942a57c63a7fe59b495a78</td>\n",
       "      <td>39.1 -96.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55942a58c63a7fe59b495a79</td>\n",
       "      <td>39.1, -96.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55942a58c63a7fe59b495a7a</td>\n",
       "      <td>-180.0 -55.0 180.0 90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55942a58c63a7fe59b495a7b</td>\n",
       "      <td>-180.0 -55.0 180.0 90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                  spatial\n",
       "0  55942a57c63a7fe59b495a77               39.1 -96.6\n",
       "1  55942a57c63a7fe59b495a78               39.1 -96.6\n",
       "2  55942a58c63a7fe59b495a79              39.1, -96.6\n",
       "3  55942a58c63a7fe59b495a7a  -180.0 -55.0 180.0 90.0\n",
       "4  55942a58c63a7fe59b495a7b  -180.0 -55.0 180.0 90.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spatialdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for exploratory visualization, I'm ignoring entries that are not comma or space-delimited double values. In this cell, we print out these entries so that future code can correctly handle them. Some of these entries are even in xml-format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:9825\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>-89.0\n",
      "-180.0</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:9825\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>-89.0\n",
      "-180.0</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:9825\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>-89.0\n",
      "-180.0</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:9825\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>-89.0\n",
      "-180.0</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:LineString\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:9825\">41.0\n",
      "-93.0</gml:LineString>\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Global\n",
      "Lunar\n",
      "asia\n",
      "africa\n",
      "australia\n",
      "antarctica\n",
      "asia\n",
      "africa\n",
      "australia\n",
      "antarctica\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Global\n",
      "Global\n",
      "Callisto\n",
      "Callisto\n",
      "Callisto\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "Earth\n",
      "regional\n",
      "global\n",
      "global\n",
      "global\n",
      "global\n",
      "global\n",
      "United\n",
      "States\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "Lunar\n",
      "World\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n",
      "<?xml\n",
      "version=\"1.0\"\n",
      "encoding=\"UTF-8\"?><gml:Polygon\n",
      "xmlns:gml=\"http://www.opengis.net/gml/3.2\"\n",
      "srsName=\"EPSG:4326\"><gml:outerBoundaryIs><gml:LinearRing><gml:posList>64.6238772\n",
      "-9.140625</gml:posList></gml:LinearRing></gml:outerBoundaryIs><gml:innerBoundaryIs></gml:innerBoundaryIs></gml:Polygon>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def splitNumbers(spatialString):\n",
    "    strList = re.split(' |,', spatialString)  \n",
    "    numList = []\n",
    "    for strval in strList:        \n",
    "        strval = strval.strip()\n",
    "        if len(strval) > 0:\n",
    "            try:\n",
    "                numList.append(float(strval))\n",
    "            except:\n",
    "                # Print location entries that we are not successfully parsing for now\n",
    "                print(strval)\n",
    "    return numList\n",
    "    \n",
    "# The code here is based on information from http://kb.tableau.com/articles/knowledgebase/convert-latitude-longitude\n",
    "def convertSpatial(spatialEntry):\n",
    "    numList = splitNumbers(spatialEntry)\n",
    "    endPoint = len(numList)\n",
    "    midPoint = len(numList)/2\n",
    "    \n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    for i in range (0, midPoint):\n",
    "        latitude.append(numList[i])\n",
    "    \n",
    "    for j in range (midPoint, endPoint):\n",
    "        longitude.append(numList[i])\n",
    "    \n",
    "    if len(latitude) > 2:\n",
    "        clatitude = latitude[0] + (latitude[1]/60) + (latitude[2]/3600)\n",
    "    elif len(latitude) > 1:\n",
    "        clatitude = latitude[0] + (latitude[1]/60)\n",
    "    elif len(latitude) > 0:\n",
    "        clatitude = latitude[0]  \n",
    "    else:\n",
    "        clatitude = None\n",
    "    \n",
    "    if len(longitude) > 2:\n",
    "        clongitude = -1*(longitude[0] + (longitude[1]/60) + (longitude[2]/3600))\n",
    "    elif len(longitude) > 1:\n",
    "        clongitude = -1*(longitude[0] + (longitude[1]/60))\n",
    "    elif len(longitude) > 0:\n",
    "        clongitude = -1*(longitude[0])\n",
    "    else:\n",
    "        clongitude = None\n",
    "        \n",
    "    return clatitude, clongitude\n",
    "\n",
    "latitudeColumn = []\n",
    "longitudeColumn = []\n",
    "for entry in spatialdf.spatial:\n",
    "    latitude, longitude = convertSpatial(entry)\n",
    "    latitudeColumn.append(latitude)\n",
    "    longitudeColumn.append(longitude)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spatialdf['latitude'] = latitudeColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spatialdf['longitude'] = longitudeColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spatial</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55942a57c63a7fe59b495a77</td>\n",
       "      <td>39.1 -96.6</td>\n",
       "      <td>39.100000</td>\n",
       "      <td>-39.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55942a57c63a7fe59b495a78</td>\n",
       "      <td>39.1 -96.6</td>\n",
       "      <td>39.100000</td>\n",
       "      <td>-39.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55942a58c63a7fe59b495a79</td>\n",
       "      <td>39.1, -96.6</td>\n",
       "      <td>39.100000</td>\n",
       "      <td>-39.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55942a58c63a7fe59b495a7a</td>\n",
       "      <td>-180.0 -55.0 180.0 90.0</td>\n",
       "      <td>-180.916667</td>\n",
       "      <td>55.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55942a58c63a7fe59b495a7b</td>\n",
       "      <td>-180.0 -55.0 180.0 90.0</td>\n",
       "      <td>-180.916667</td>\n",
       "      <td>55.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                  spatial    latitude  longitude\n",
       "0  55942a57c63a7fe59b495a77               39.1 -96.6   39.100000 -39.100000\n",
       "1  55942a57c63a7fe59b495a78               39.1 -96.6   39.100000 -39.100000\n",
       "2  55942a58c63a7fe59b495a79              39.1, -96.6   39.100000 -39.100000\n",
       "3  55942a58c63a7fe59b495a7a  -180.0 -55.0 180.0 90.0 -180.916667  55.916667\n",
       "4  55942a58c63a7fe59b495a7b  -180.0 -55.0 180.0 90.0 -180.916667  55.916667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatialdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('nasa_spatial3.csv', 'wb')\n",
    "fieldnames = ['doc_id', 'latitude', 'longitude']\n",
    "w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "w.writeheader()\n",
    "\n",
    "for index, row in spatialdf.iterrows():\n",
    "    w.writerow({'doc_id': row['id'].encode('utf-8'), 'latitude': row['latitude'], 'longitude': row['longitude']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of data location in Tableau\n",
    "After the data reformatting above, we can finally visualize where each data (source?) is located in a map in Tableau https://public.tableau.com/views/NASAOpenDataMetadatatopic-predictionusingLDAbuiltfromWikipediacorpus/Sheet6\n",
    "\n",
    "However, the data format seems suspect to me due to the two distinct lines - one at the bottom of the map, and another diagonally across the globe. We will have to contact some NASA experts to verify if the visualization is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
